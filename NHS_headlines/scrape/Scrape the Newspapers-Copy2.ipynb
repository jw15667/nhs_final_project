{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from requests import get\n",
    "from random import randint\n",
    "PATH = (\"C:/Users/jw156/Ironhack/CareerHack/chromedriver.exe\")\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the headline, first para.\n",
    "2. date: newspaper: tabload or broad: text: sentiment\n",
    "3. Shuffle the dataset and kmeans.\n",
    "shuffle the dataset, before and after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the dates between Date Range "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim: The lockdown began on 16 March 2020, when Matt Hancock told the House of Commons that all unnecessary social contact should cease.\n",
    "\n",
    "Look at articles 6 months before and 6 months afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start 6 months before: '16 September 2018' \n",
    "# Finish 6 months afterwards: '16 September 2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdate = date(2019, 9, 16)   # start date\n",
    "edate = date(2020, 9, 16)   # end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency weekly, get all the weekly articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_search_dates = pd.date_range(sdate,edate-timedelta(days=1),freq='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing format so it matches google requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_days = [day.strftime('%m-%d-%Y') for day in all_search_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium Search Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_selenium(subject, website):\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from random import randint\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "    #will search on google\n",
    "    driver.get('http://www.google.com')\n",
    "    search = driver.find_element_by_name('q')\n",
    "    random_i = randint(5, 15)\n",
    "    driver.implicitly_wait(random_i)\n",
    "    # Enter search \n",
    "    search.send_keys(f'{subject} site:{website}')\n",
    "    # hit return after you enter search text\n",
    "    search.send_keys(Keys.RETURN) \n",
    "    get_hundred_results = str(driver.current_url)\n",
    "    temporary_url = get_hundred_results + '&num=100'\n",
    "    driver.get(temporary_url)\n",
    "    return driver\n",
    "\n",
    "def enter_date(driver, start_date, end_date):\n",
    "    from random import randint\n",
    "    # Find the tool bar\n",
    "    element = driver.find_element_by_id('hdtb-tls')\n",
    "    driver.execute_script(\"arguments[0].click();\", element)\n",
    "    #sleep\n",
    "#     random_i = randint(5, 15)\n",
    "#     driver.implicitly_wait(random_i)\n",
    "    # Click on the date bar\n",
    "    element2 = driver.find_element_by_class_name('hdtb-mn-hd')\n",
    "    driver.execute_script(\"arguments[0].click();\", element2)\n",
    "    # Find the Customer Range menu\n",
    "    element3 = driver.find_element_by_class_name('ErsxPb.gvybPb')\n",
    "    driver.execute_script(\"arguments[0].click();\", element3)\n",
    "    #sleep\n",
    "#     random_i = randint(5, 15)\n",
    "#     driver.implicitly_wait(random_i)\n",
    "    # Click the Customer Range menu\n",
    "    element4 = WebDriverWait(driver, 25).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"lb\"]/div[2]/g-menu/g-menu-item[7]/div/div/span')))\n",
    "    driver.execute_script(\"arguments[0].click();\", element4)\n",
    "    # Input Start Date\n",
    "    element5 = driver.find_element_by_xpath('//*[@id=\"OouJcb\"]')\n",
    "    element5.send_keys(start_date)\n",
    "    # Input End Date\n",
    "    element6 = driver.find_element_by_xpath('//*[@id=\"rzG2be\"]')\n",
    "    element6.send_keys(end_date)\n",
    "    # Random Sleep\n",
    "#     random_i = randint(5, 15)\n",
    "#     driver.implicitly_wait(random_i)\n",
    "    # Submit Date\n",
    "    element7 = driver.find_element_by_xpath('//*[@id=\"T3kYXe\"]/g-button')\n",
    "    driver.execute_script(\"arguments[0].click();\", element7)\n",
    "    return driver\n",
    "\n",
    "def find_hrefs(driver, list_articles):\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from random import randint\n",
    "    random_i = randint(5, 15)\n",
    "    driver.implicitly_wait(random_i)\n",
    "    results = driver.find_elements_by_css_selector('div.g')\n",
    "    for i in range(len(results)):\n",
    "        random_i = randint(5, 15)\n",
    "        driver.implicitly_wait(random_i)\n",
    "        link = results[i].find_element_by_tag_name(\"a\")\n",
    "        href = link.get_attribute(\"href\")\n",
    "        list_articles.append(href)\n",
    "    return list_articles, driver\n",
    "\n",
    "def next_page(driver):\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from random import randint\n",
    "    try:\n",
    "        random_i = randint(5, 15)\n",
    "        time.sleep(random_i)\n",
    "        next_page = driver.find_element_by_xpath(\"//*[@id='pnnext']\").get_attribute(\"href\")\n",
    "        random_i = randint(5, 15)\n",
    "        driver.implicitly_wait(random_i)\n",
    "        driver.get(next_page)\n",
    "        no_more_pages = False\n",
    "        return no_more_pages\n",
    "    \n",
    "    except:\n",
    "        print(\"no more pages left\")\n",
    "        no_more_pages = True\n",
    "        return no_more_pages\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to scrape hrefs\n",
    "\n",
    "##### Selenium\n",
    "- Use Selenium to google search each week within the desired timeframe. \n",
    "- Click through to page 2 and then quit, so each unique url can be gerated to include page tag.\n",
    "- Create a list of 54 urls\n",
    "\n",
    "##### Beautiful Soup\n",
    "- Use Beautiful Soup to loop through each page and return the hrefs for every google page.\n",
    "- For loop through each url until no more, then exit and continue on next url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.reddit.com/r/webscraping/comments/iegnoo/scraping_100_google_search_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = ['dailymail.co.uk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c5e0ffeb2fda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mend_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_days\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mdated_website\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menter_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mgoogle_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdated_website\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mgoogle_urls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoogle_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-2eff02d6e655>\u001b[0m in \u001b[0;36menter_date\u001b[1;34m(driver, start_date, end_date)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Click the Customer Range menu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0melement4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'//*[@id=\"lb\"]/div[2]/g-menu/g-menu-item[7]/div/div/span'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arguments[0].click();\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Input Start Date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from random import randint\n",
    "\n",
    "i = 0\n",
    "for website in websites:\n",
    "    for x in range(6):\n",
    "        search_result = search_selenium('nhs', website)\n",
    "        start_date = search_days[i]\n",
    "        end_date = search_days[i + 4]\n",
    "        i += 4\n",
    "        dated_website = enter_date(search_result, start_date, end_date)\n",
    "        google_page = dated_website.current_url\n",
    "        google_urls.append(google_page)\n",
    "        random_i = randint(30,180)\n",
    "        time.sleep(random_i)\n",
    "\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-fb6ca735815a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mrandom_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mno_more_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdated_website\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mgoogle_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdated_website\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "from random import randint\n",
    "\n",
    "i = 0\n",
    "for website in websites:\n",
    "    for x in range(12):\n",
    "        search_result = search_selenium('nhs', website)\n",
    "        get_hundred_results = str(search_result.current_url) + '&num=100'\n",
    "        start_date = search_days[i]\n",
    "        end_date = search_days[i + 4]\n",
    "        dated_website = enter_date(get_hundred_results, start_date, end_date)\n",
    "        i += 4\n",
    "        print(i)\n",
    "        for s in range(1):\n",
    "            random_i = randint(30, 180)\n",
    "            time.sleep(random_i)\n",
    "            no_more_pages = next_page(dated_website)\n",
    "            google_page = dated_website.current_url\n",
    "            google_urls.append(google_page)\n",
    "            \n",
    "\n",
    "print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_tagged_urls_google.txt\", \"w\") as output:\n",
    "    output.write(str(final_urls_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop through urls and generate all urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ = []\n",
    "for i in range(10, 410, 10):\n",
    "    start_.append(f'start={i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_urls_list = []\n",
    "for url in google_urls:    \n",
    "    first_url = url.split('start=10')\n",
    "    for i in range(len(start_)):\n",
    "        final_urls_list.append(start_[i].join(first_url))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape hrefs google searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dailymail.co.uk/health/article-7503905/UK-health-officials-approve-life-changing-spina-bifida-surgery-WOMB.html\n",
      "https://www.dailymail.co.uk/news/article-7518285/Deaf-blind-Medical-student-25-refuses-let-disabilities-stop-NHS-doctor.html\n",
      "https://www.dailymail.co.uk/health/article-7511315/Thousands-patients-wait-extra-TWO-WEEKS-winter-flu-jab.html\n",
      "https://www.dailymail.co.uk/femail/food/article-7505565/Tuck-chocolate-puddings-cakes-guilt-free-low-carb-recipes-NHS-expert.html\n",
      "https://www.dailymail.co.uk/health/article-7515637/Intense-one-blast-radiotherapy-brings-new-hope-pancreatic-cancer-patients.html\n",
      "https://www.dailymail.co.uk/health/article-7507111/Vaccine-coverage-falls-13-childhood-jabs-England-year.html\n",
      "https://www.dailymail.co.uk/health/article-7518701/Pain-expert-JONATHAN-GORNALL-reveals-stop-little-aches-arthritis.html\n",
      "https://www.dailymail.co.uk/femail/article-7495425/10-brands-help-feel-look-live-better.html\n",
      "https://www.dailymail.co.uk/health/article-7496665/New-mobile-phone-app-lets-dentists-prescribe-antibiotics-video-call.html\n",
      "https://www.dailymail.co.uk/health/article-7501259/Delicious-dinner-recipes-fight-diabetes-guests-wont-know-healthy.html\n",
      "https://www.dailymail.co.uk/health/article-7495931/Mouth-watering-breakfast-recipes-help-beat-diabetes.html\n",
      "https://www.dailymail.co.uk/health/article-7508599/BBC-documentary-reveals-UK-exports-anti-vaxx-myths-rest-world.html\n",
      "https://www.dailymail.co.uk/health/article-7498417/Mothers-not-push-child-naturally-C-section-complications.html\n",
      "https://www.dailymail.co.uk/health/article-7498321/Artificial-intelligence-diagnose-illnesses-accuracy-trained-doctors-study-finds.html\n",
      "https://www.dailymail.co.uk/health/article-7511505/Stillborn-baby-survived-common-infection-d.html\n",
      "https://www.dailymail.co.uk/health/article-7515235/Give-ADULT-cancer-fighting-HPV-jab-save-thousands-lives-experts-demand.html\n",
      "https://www.dailymail.co.uk/health/article-7493621/Men-small-steps-40-likely-erectile-dysfunction.html\n",
      "https://www.dailymail.co.uk/health/fb-7494911/WHAT-ECTOPIA-CORDIS.html\n",
      "https://www.dailymail.co.uk/health/article-7497729/EU-approves-time-use-cannabis-based-product-childhood-epilepsy.html\n",
      "https://www.dailymail.co.uk/health/article-7493907/Hopes-herpes-vaccine-study-experimental-jab-prevented-spread.html\n",
      "https://www.dailymail.co.uk/health/article-7511691/Radiotherapy-does-not-decrease-chance-prostate-cancer-returning-study-finds.html\n",
      "https://www.dailymail.co.uk/health/article-7508315/The-teething-gels-contain-sugar-alcohol-controversial-anaesthetic.html\n",
      "https://www.dailymail.co.uk/news/article-7491553/Coroner-links-deaths-FIVE-women-suffered-eating-disorders.html\n",
      "https://www.dailymail.co.uk/femail/article-7502997/Mumsnet-users-share-WORST-work-stories-shocking-thread.html\n",
      "https://www.dailymail.co.uk/health/article-7494367/Woman-60-develops-broken-heart-syndrome-eating-teaspoon-wasabi.html\n",
      "https://www.dailymail.co.uk/news/article-7518913/British-factory-worker-57-worlds-person-die-disease-linked-VAPING.html\n",
      "https://www.dailymail.co.uk/health/article-7508489/Test-predict-deadliest-form-skin-cancer-likely-spread-return.html\n",
      "https://www.dailymail.co.uk/femail/food/article-7492499/David-Unwin-reveals-mouth-watering-recipes-help-fight-diabetes.html\n",
      "https://www.dailymail.co.uk/health/article-7495891/Doctors-handing-safer-painkillers-experts-fear-dangerous-opioids.html\n",
      "https://www.dailymail.co.uk/health/article-7502765/Electrical-stimulation-zaps-away-cluster-headaches-relieve-vertigo.html\n",
      "https://www.dailymail.co.uk/health/article-7511489/Couple-met-Crohns-support-Facebook-group-engaged.html\n",
      "https://www.dailymail.co.uk/health/article-7498663/Eating-fruit-vegetables-fish-slashes-persons-risk-chronic-kidney-disease-30.html\n",
      "https://www.dailymail.co.uk/news/article-7492007/Trump-receives-endorsement-Indias-prime-minister-goes-Indian-American-vote.html\n",
      "https://www.dailymail.co.uk/health/article-7506789/Woman-breaks-blotchy-purple-rash-caused-cold-New-York-weather.html\n",
      "https://www.dailymail.co.uk/femail/article-7518085/My-lightbulb-moment-Skincare-innovator-Antonia-Philp-reveals-inspiration-beauty-range.html\n",
      "https://www.dailymail.co.uk/femail/article-7491201/Lena-Dunham-opened-booking-mental-health-facility.html\n",
      "https://www.dailymail.co.uk/health/article-7507085/Experimental-drug-type-2-diabetes-lowers-blood-sugar-boosts-weight-loss-obese-mice.html\n",
      "https://www.dailymail.co.uk/health/article-7505309/DONT-kiss-babies-warns-mother-nearly-lost-son-infection.html\n",
      "https://www.dailymail.co.uk/video/news/video-2014672/Video-Tesco-employee-explodes-anger-rants-job.html\n",
      "https://www.dailymail.co.uk/health/article-7496809/One-Britains-longest-surviving-transplant-patients-speaks-out.html\n",
      "https://www.dailymail.co.uk/news/article-7518371/Women-driven-brink-Britains-social-care-crisis.html\n",
      "https://www.dailymail.co.uk/health/article-7422619/Men-desperate-chiselled-jaw-chewing-rubber-ball-bizarre-new-trend.html\n",
      "https://www.dailymail.co.uk/health/article-7515723/DR-MICHAEL-MOSLEY-Flu-killed-heres-fight-winter.html\n",
      "https://www.dailymail.co.uk/health/article-7435903/Ehlers-Danlos-patients-warned-greater-risk-fracturing-penis.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7498747/Amy-Childs-reveals-jailbird-ex-Bradley-Wright-bars.html\n",
      "https://www.dailymail.co.uk/femail/food/article-7499673/Marys-awesome-autumn-feasts-Loch-Fyne-haddock-bake.html\n",
      "https://www.dailymail.co.uk/health/article-7498409/Eating-onions-garlic-day-reduces-womans-risk-breast-cancer-67.html\n",
      "https://www.dailymail.co.uk/health/article-7496155/DR-XAND-VAN-TULLEKEN-Daily-Mails-health-diary-changing-habits.html\n",
      "https://www.dailymail.co.uk/health/article-7496767/DR-MARTIN-SCURR-bathing-bleach-ease-dry-cracked-skin.html\n",
      "https://www.dailymail.co.uk/health/article-7506793/HIV-cure-one-step-closer-scientists-kill-switch-stops-reproduction-cells.html\n",
      "https://www.dailymail.co.uk/health/article-7499021/Queer-Eye-star-Jonathan-Van-Ness-opens-day-learned-HIV-positive.html\n",
      "https://www.dailymail.co.uk/health/article-7494925/Youngest-children-school-year-36-likely-depression.html\n",
      "https://www.dailymail.co.uk/femail/article-7504389/How-Pill-transforms-personality-revealed-landmark-book-psychologist.html\n",
      "https://www.dailymail.co.uk/news/article-7509701/Hearty-low-carb-feasts-help-fuel-way-fitness-fight-against-diabetes.html\n",
      "https://www.dailymail.co.uk/femail/article-7477229/Feel-inside-supported-gut-key-feeling-good.html\n",
      "https://www.dailymail.co.uk/health/article-7492625/Sex-addiction-caused-cuddle-hormone-oxytocin-study-suggests.html\n",
      "https://www.dailymail.co.uk/health/article-7512393/Salt-shakers-food-packaging-tobacco-style-health-warning.html\n",
      "https://www.dailymail.co.uk/health/article-7493807/Sun-worshipper-left-gaping-hole-nose-developing-skin-cancer-sun-beds.html\n",
      "https://www.dailymail.co.uk/health/article-7512311/Cancer-sufferer-five-wanted-tattoo-artist-lives-dream.html\n",
      "https://www.dailymail.co.uk/health/article-7506857/How-bacteria-SUPERBUGS.html\n",
      "https://www.dailymail.co.uk/femail/article-7456085/Mother-recalls-moment-husband-told-needed-11-weeks-premature-son-quickly.html\n",
      "https://www.dailymail.co.uk/health/article-7512263/British-backpacker-fighting-life-Vietnam-hospital-pneumonia.html\n",
      "https://www.dailymail.co.uk/femail/article-7517499/Kindergarten-teacher-branded-hero-crafting-glitter-hearing-aids-deaf-pupils-dolls.html\n",
      "https://www.dailymail.co.uk/health/article-7515569/Risk-free-mouth-swab-DNA-test-reveals-surgery-patients-risk-scarring-badly.html\n",
      "https://www.dailymail.co.uk/health/article-7503589/Men-children-fertility-treatments-likely-develop-prostate-cancer.html\n",
      "https://www.dailymail.co.uk/health/article-7514107/Take-pain-quiz-reveal-levels-experience-day-day.html\n",
      "https://www.dailymail.co.uk/femail/article-7511935/Hollywood-bikini-model-undergoes-8-000-bum-lift-procedure-Beverly-Hills-party.html\n",
      "https://www.dailymail.co.uk/health/article-7507041/Hope-millions-hearing-loss-scientists-44-genes-linked-age-related-deafness.html\n",
      "https://www.dailymail.co.uk/health/fb-7500099/WHAT-SPINA-BIFIDA.html\n",
      "https://www.dailymail.co.uk/femail/article-7496805/Aldi-launch-cheap-barbeque-new-special-buys.html\n",
      "https://www.dailymail.co.uk/health/article-7499129/The-urine-test-detect-pancreatic-cancer-increase-survival-rates-50.html\n",
      "https://www.dailymail.co.uk/health/article-7507473/Teenagers-likely-homework-mothers-tell-controlling-tone.html\n",
      "https://www.dailymail.co.uk/video/news/video-2010902/Video-Ukrainian-President-hilariously-starts-presentation-using-WhatsApp.html\n",
      "https://www.dailymail.co.uk/femail/article-7517475/Queen-dons-lime-green-hat-attends-Sunday-church-service-Balmoral.html\n",
      "https://www.dailymail.co.uk/health/article-7506891/Mother-told-lump-breast-benign-told-cancerous-six-months-later-pregnant.html\n",
      "https://www.dailymail.co.uk/news/article-7505261/Rock-drummer-Ginger-Baker-80-critically-ill-hospital-three-years-heart-surgery.html\n",
      "https://www.dailymail.co.uk/femail/article-7490855/EXACTLY-happens-body-sit-Experts-reveal-bad-health.html\n",
      "https://www.dailymail.co.uk/health/article-7494665/New-York-man-hit-650-000-medical-bills-surgery-save-paralysis.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dailymail.co.uk/health/article-7493631/Woman-born-TWO-vaginas-TWO-cervixes-mother-four.html\n",
      "https://www.dailymail.co.uk/health/article-7502377/Taking-placebo-cure-exam-anxiety-know-pills-dont-contain-drugs.html\n",
      "https://www.dailymail.co.uk/health/article-7495221/High-school-football-player-clinging-life-tangle-blood-vessels-brain-burst.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7501833/Ruby-Rose-defends-against-online-haters-slammed-casting-Batwoman.html\n",
      "https://www.dailymail.co.uk/health/article-7503443/Minimum-unit-pricing-Scotland-worked-slashed-alcohol-purchased-8.html\n",
      "https://www.dailymail.co.uk/femail/food/article-7497781/Cadbury-fans-wild-orange-flavoured-Twirl-finally-launches.html\n",
      "https://www.dailymail.co.uk/health/article-7495177/Eating-half-ounce-nuts-day-cuts-odds-gaining-weight.html\n",
      "https://www.dailymail.co.uk/femail/article-7491205/Zara-Tindall-rising-ranks-74th-eighth-Blenheim-Palace-Horse-Trials.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7512345/Louis-Tomlinsons-sister-Lottie-Chelsea-star-Sam-Prince-split.html\n",
      "https://www.dailymail.co.uk/femail/article-7504267/Girl-diagnosed-tumour-attached-brain-right-eye-hope-future.html\n",
      "https://www.dailymail.co.uk/news/article-7515387/Meghan-Markle-glittery-princess-vest-star-new-episodes-Spitting-Image.html\n",
      "https://www.dailymail.co.uk/news/article-7496661/Adelaide-cleaner-Negar-Ghodskani-faces-11-years-jail-smuggling-sensitive-technology-Iran.html\n",
      "https://www.dailymail.co.uk/health/article-7499105/Fish-eggs-fertilised-frozen-sperm-grow-4-2-slower-produced-fresh-swimmers.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7516779/Love-Island-Australia-Cartier-Rose-says-love-Jesus.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7501299/The-Voice-loop-artist-marries-gamer-girlfriend-Liberty-Hills.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7514237/Downton-Abbey-star-Tuppence-Middleton-splits-long-term-boyfriend-artist-Robert-Fry.html\n",
      "https://www.dailymail.co.uk/femail/article-7517169/Queen-delighted-Meghan-Markle-Prince-Harrys-uniquely-informal-tour-expert-says.html\n",
      "https://www.dailymail.co.uk/femail/food/article-7499569/Marys-awesome-autumn-feasts-Creme-brulee-chocolate-pots.html\n",
      "https://www.dailymail.co.uk/femail/article-7498535/Mrs-Hinch-breaks-cruel-trolls-brand-baby-ugly.html\n",
      "https://www.dailymail.co.uk/news/article-7506791/Boris-Johnson-dropped-pole-dancing-friend-Jennifer-Arcuri-like-stone.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7516541/Strictlys-Michelle-Visage-reveals-fans-think-shes-man.html\n",
      "https://www.dailymail.co.uk/femail/food/article-7499661/Marys-awesome-autumn-feasts-Highland-game-pie.html\n",
      "https://www.dailymail.co.uk/health/article-7496733/Distraught-mother-speaks-child-died-common-infection.html\n",
      "https://www.dailymail.co.uk/news/article-7515915/Eagle-eyed-photographer-captures-leopard-hiding-ditch-SPOT-it.html\n",
      "https://www.dailymail.co.uk/femail/article-7418729/Celebrity-make-artist-Danny-Defreitas-shares-tips-flawless-skin-skin-type.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7492335/Chris-Elsa-fear-Hollywood-suffocating-Liam.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7501879/Beyonce-declares-Blue-Ivy-Carter-cultural-icon-amid-legal-battle-trademark-daughters-name.html\n",
      "https://www.dailymail.co.uk/femail/article-7513477/People-reveal-pop-culture-moment-RUINED-name.html\n",
      "https://www.dailymail.co.uk/news/article-7491627/Ukraines-president-trolls-world-leaders-spoof-WhatsApp-group.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7501177/Did-Sophie-Monk-lip-fillers-dissolved.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7516211/TALK-TOWN-Bad-hair-days-troubling-Iris-Law-Sofia-Abramovich-Anais-Gallagher.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7493121/Hugh-Jackman-reveals-BANNED-daughter-Avas-dance-class.html\n",
      "https://www.dailymail.co.uk/news/article-7510211/Lee-Boxell-missing-31-years-Cheam-Surrey-killed-sex-attacker.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7497935/Matthew-Davis-reveals-expecting-child-wife-Kiley-Casciano.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7500915/Kate-Lawler-39-reveals-shes-worried-partner-divorce-her.html\n",
      "https://www.dailymail.co.uk/news/article-7515013/Lottery-conman-accused-tricking-three-grandmothers-400-000-living-Vietnam.html\n",
      "https://www.dailymail.co.uk/sitemap-articles-day~2019-09-29.xml\n",
      "https://www.dailymail.co.uk/health/article-7512227/Black-market-cannabis-vapes-contain-hydrogen-CYANIDE.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7518779/Nicky-Hilton-shares-photo-James-Rothschild-enjoying-daddy-daughter-beach-day-Lily-Grace-3.html\n",
      "https://www.dailymail.co.uk/news/article-7510997/Russian-beauty-baby-ex-Malaysia-king-tells-fairy-tale-marriage-collapsed.html\n",
      "https://www.dailymail.co.uk/femail/article-7510911/Inside-luxurious-life-Jinkee-Pacquiao-meeting-husband-Manny-mall-aged-20.html\n",
      "https://www.dailymail.co.uk/femail/article-7495051/Couple-create-dream-home-building-YURT.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7511743/Holliday-Grainger-Tom-Burke-seen-time-set-Lethal-White.html\n",
      "https://www.dailymail.co.uk/tvshowbiz/article-7492771/Game-Thrones-stars-Emilia-Clarke-Gwendoline-Christie-hit-Emmys-red-carpet.html\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-10c0352e49c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfinal_urls_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mrandom_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'User-Agent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "import re \n",
    "import time \n",
    "\n",
    "daily_mail_hrefs = []\n",
    "for link in final_urls_list:\n",
    "    random_i = randint(5, 15)\n",
    "    time.sleep(random_i)\n",
    "    URL = link\n",
    "    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n",
    "    resp = requests.get(URL, headers=headers).text \n",
    "    soup = BeautifulSoup(resp, 'html.parser')\n",
    "    pattern = '^https://www.dailymail.co.uk/'\n",
    "    for link in soup.findAll('a', href=True): \n",
    "        if link.get('href').startswith('https://www.dailymail.co.uk/'):\n",
    "            print(link.get('href'))\n",
    "            daily_mail_hrefs.append(link.get('href'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_mail = []\n",
    "\n",
    "for href in daily_mail_hrefs:\n",
    "    if 'https://www.dailymail' in href:\n",
    "        daily_mail.append(href)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup - Headlines and Straplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily_mail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-42922199444c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marticle_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheadline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0marticle_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheadline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_daily_mail_headlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdaily_mail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'daily_mail' is not defined"
     ]
    }
   ],
   "source": [
    "def scrape_daily_mail_headlines(list_urls):\n",
    "    article_text = []\n",
    "    dates = []\n",
    "    headline = []\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    for i in range(len(list_urls)):\n",
    "        req = requests.get(daily_mail[i])\n",
    "        soup = BeautifulSoup(req.content, 'html.parser')\n",
    "        # find the headlines\n",
    "        article_headline = soup.find('h2').text\n",
    "        headline.append(article_headline)\n",
    "        # find the straplines\n",
    "        for ultag in soup.find_all('ul', {'class': 'mol-bullets-with-font'}):\n",
    "            local_list = []\n",
    "            for litag in ultag.find_all('li'):\n",
    "                text = litag.text\n",
    "                local_list.append(text)\n",
    "        article_text.append(local_list)\n",
    "            \n",
    "        # get the timestamp\n",
    "        try:\n",
    "            date_time = soup.find('time').text\n",
    "            article_date = date_time.split(',')[1]\n",
    "            dates.append(article_date)\n",
    "        except:\n",
    "            dates.append(\"No date given\")\n",
    "\n",
    "    return article_text, dates, headline\n",
    "\n",
    "article_text, dates, headline = scrape_daily_mail_headlines(daily_mail_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"daily_mail_article_text.txt\", \"w\") as output:\n",
    "    for s in article_text:\n",
    "        outfile.write(\"%s\\n\" % s)\n",
    "\n",
    "    output.write(str(article_text))\n",
    "\n",
    "with open(\"daily_mail_dates.txt\", \"w\") as output:\n",
    "    for s in dates:\n",
    "        outfile.write(\"%s\\n\" % s)\n",
    "\n",
    "with open(\"daily_mail_headline.txt\", \"w\") as output:\n",
    "    for s in headline:\n",
    "        outfile.write(\"%s\\n\" % s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Google with Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# url = 'https://www.google.com/search?sxsrf=ALeKk01NCXLLm0RJBab9tu4aUEXHyabIKQ%3A1614890859311&ei=a0dBYJnGEoSjgQaK4o4g&q=nhs+site%3Adailymail.co.uk&oq=nhs+si&gs_lcp=Cgdnd3Mtd2l6EAMYADIECCMQJzIECCMQJzIECCMQJzICCAAyAggAMgIIADICCAAyAggAMgIIADICCAA6BwgjELADECc6BwgAELADEEM6BwgAEEcQsAM6BQgAEJECOgsILhCxAxDHARCjAjoFCAAQsQM6CAgAELEDEIMBOg4ILhCxAxCDARDHARCjAjoICC4QsQMQgwE6CgguELEDEIMBEEM6BAgAEEM6BwgAELEDEEM6CggAELEDEIMBEEM6BQgAEMkDOgQIABAKOggIABAWEAoQHjoGCAAQFhAeUJ7XDljT6w5g6fEOaAVwAXgAgAHLAogBow2SAQcxLjUuMi4xmAEAoAEBqgEHZ3dzLXdpesgBCsABAQ&sclient=gws-wiz'\n",
    "# req = requests.get(url)\n",
    "# soup = BeautifulSoup(req.content, 'html.parser')\n",
    "# # find the headlines\n",
    "# # results = soup.find_all('div', attrs={\"class\":\"home-summary-row\"})\n",
    "\n",
    "# import re\n",
    "\n",
    "# for a in soup.find_all('a', href=True):\n",
    "#     if \"https://www.dailymail.co.uk/\" in a['href']:\n",
    "#         href = a['href']\n",
    "#         real_href = re.split(\"//\", href)\n",
    "#         print(href)\n",
    "#         print(\"---------------------------\")\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time \n",
    "# from random import randint\n",
    "\n",
    "# i = 0\n",
    "# for website in websites:\n",
    "#     for x in range(26):\n",
    "#         search_result = search_selenium('nhs', website)\n",
    "#         start_date = search_days[i]\n",
    "#         end_date = search_days[i + 1]\n",
    "#         dated_website = enter_date(search_result, start_date, end_date)\n",
    "#         i += 1\n",
    "#         print(i)\n",
    "#         no_more_pages = False\n",
    "#         while no_more_pages == False:\n",
    "#             list_articles, driver = find_hrefs(dated_website, list_articles)\n",
    "#             random_i = randint(5, 15)\n",
    "#             time.sleep(random_i)\n",
    "#             no_more_pages = next_page(driver)\n",
    "\n",
    "# print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.dailymail.co.uk/news/article-9320239/NHS-hospitals-London-told-prepare-possible-surge-Covid-patients-later-year.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# req = requests.get(daily_mail[701])\n",
    "# soup = BeautifulSoup(req.content, 'html.parser')\n",
    "# # find the headlines\n",
    "# soup.find('h2').text\n",
    "\n",
    "# # find the straplines\n",
    "# for ultag in soup.find_all('ul', {'class': 'mol-bullets-with-font'}):\n",
    "#     for litag in ultag.find_all('li'):\n",
    "#         print(litag.text)\n",
    "#         print('----------------------------')\n",
    "\n",
    "# # get the timestamp\n",
    "# date_time = soup.find('time').text\n",
    "# date = date_time.split(',')[1]\n",
    "# date\n",
    "\n",
    "\n",
    "# # soup = BeautifulSoup(url2)\n",
    "# # print(soup)\n",
    "# # headline_selector = soup.find_all('div', class_='//*[@id=\"js-article-text\"]')\n",
    "# # print(headline_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(PATH)\n",
    "# # will search on google\n",
    "# driver.get('https://www.google.com/search?q=nhs+site:theguardian.com&tbs=cdr:1,cd_min:03-23-2019,cd_max:03-30-2019&ei=IgBAYKqiFrPPxgOSuoLYBQ&start=220&sa=N&ved=2ahUKEwiqu7GQiZXvAhWzp3EKHRKdAFs4jgIQ8tMDegQIBhBD&biw=1036&bih=529&dpr=1.5')\n",
    "# element = driver.find_element_by_id('hdtb-tls')\n",
    "# driver.execute_script(\"arguments[0].click();\", element)\n",
    "# #sleep\n",
    "# random_i = randint(5, 15)\n",
    "# driver.implicitly_wait(random_i)\n",
    "# # Click on the date bar\n",
    "# element2 = driver.find_element_by_class_name('hdtb-mn-hd')\n",
    "# driver.execute_script(\"arguments[0].click();\", element2)\n",
    "# # Find the Customer Range menu\n",
    "# element3 = driver.find_element_by_class_name('ErsxPb.gvybPb')\n",
    "# driver.execute_script(\"arguments[0].click();\", element3)\n",
    "# #sleep\n",
    "# random_i = randint(5, 15)\n",
    "# driver.implicitly_wait(random_i)\n",
    "# # Click the Customer Range menu\n",
    "# try:\n",
    "#     element4 = WebDriverWait(driver, 25).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"lb\"]/div[2]/g-menu/g-menu-item[7]/div/div/span')))\n",
    "#     driver.execute_script(\"arguments[0].click();\", element4)\n",
    "\n",
    "# except:\n",
    "#     element4 = WebDriverWait(driver, 25).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ow54\"]/span')))\n",
    "#     driver.execute_script(\"arguments[0].click();\", element4)\n",
    "# element5 = driver.find_element_by_xpath('//*[@id=\"OouJcb\"]')\n",
    "# element5.send_keys(start_date)\n",
    "# # Input End Date\n",
    "# element6 = driver.find_element_by_xpath('//*[@id=\"rzG2be\"]')\n",
    "# element6.send_keys(end_date)\n",
    "# # Random Sleep\n",
    "# random_i = randint(5, 15)\n",
    "# driver.implicitly_wait(random_i)\n",
    "# # Submit Date\n",
    "# element7 = driver.find_element_by_xpath('//*[@id=\"T3kYXe\"]/g-button')\n",
    "# driver = driver.execute_script(\"arguments[0].click();\", element7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practise Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from fake_useragent import UserAgent\n",
    "\n",
    "# options = Options()\n",
    "# ua = UserAgent()\n",
    "# userAgent = ua.random\n",
    "# print(userAgent)\n",
    "# options.add_argument(f'user-agent={userAgent}')\n",
    "# driver = webdriver.Chrome(chrome_options=options, executable_path=PATH)\n",
    "# driver.get(\"https://www.google.co.in\")\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.action_chains import ActionChains\n",
    "# import time\n",
    "\n",
    "# driver = webdriver.Chrome(PATH)\n",
    "\n",
    "# driver.get('http://www.google.com')\n",
    "\n",
    "# search = driver.find_element_by_name('q')\n",
    "# # Enter search \n",
    "# search.send_keys('nhs site:theguardian.com')\n",
    "# # hit return after you enter search text\n",
    "# search.send_keys(Keys.RETURN) \n",
    "# #Sleep\n",
    "# time.sleep(10)\n",
    "# # Find the tool bar\n",
    "# element = driver.find_element_by_id('hdtb-tls')\n",
    "# driver.execute_script(\"arguments[0].click();\", element)\n",
    "# # Click on the date bar\n",
    "# element2 = driver.find_element_by_class_name('hdtb-mn-hd')\n",
    "# driver.execute_script(\"arguments[0].click();\", element2)\n",
    "# # Find the Custom Range menu\n",
    "# element3 = driver.find_element_by_class_name('ErsxPb.gvybPb')\n",
    "# driver.execute_script(\"arguments[0].click();\", element3)\n",
    "# # Click the Custom Range menu\n",
    "# time.sleep(3)\n",
    "# element4 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"lb\"]/div[2]/g-menu/g-menu-item[7]/div/div/span')))\n",
    "# # element4 = driver.find_element_by_xpath('//*[@id=\"lb\"]/div[2]/g-menu/g-menu-item[7]/div/div/span')\n",
    "# driver.execute_script(\"arguments[0].click();\", element4)\n",
    "# # Input Start Date\n",
    "# element5 = driver.find_element_by_xpath('//*[@id=\"OouJcb\"]')\n",
    "# element5.send_keys('23-03-2019')\n",
    "# # Input End Date\n",
    "# element6 = driver.find_element_by_xpath('//*[@id=\"rzG2be\"]')\n",
    "# element6.send_keys('23-03-2019')\n",
    "# time.sleep(5)\n",
    "\n",
    "# # Submit Date\n",
    "# element7 = driver.find_element_by_xpath('//*[@id=\"T3kYXe\"]/g-button')\n",
    "# driver.execute_script(\"arguments[0].click();\", element7)\n",
    "\n",
    "\n",
    "# ## get hrefs\n",
    "# results = driver.find_elements_by_css_selector('div.g')\n",
    "# time.sleep(5)\n",
    "# for i in range(len(results)):\n",
    "#     link = results[i].find_element_by_tag_name(\"a\")\n",
    "#     href = link.get_attribute(\"href\")\n",
    "#     print(href)\n",
    "    \n",
    "# # Select next page\n",
    "\n",
    "# # while True:\n",
    "# try:\n",
    "#     next_page = driver.find_element_by_xpath(\"//*[@id='pnnext']\").get_attribute(\"href\")\n",
    "#     driver.get(next_page)\n",
    "\n",
    "# except:\n",
    "#     print(\"no more pages left\")\n",
    "#     driver.quit()\n",
    "#     False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.action_chains import ActionChains\n",
    "# import time\n",
    "\n",
    "# driver = webdriver.Chrome(PATH)\n",
    "\n",
    "# driver.get('http://www.google.com')\n",
    "\n",
    "# search = driver.find_element_by_name('q')\n",
    "# # Enter search \n",
    "# search.send_keys('nhs site:theguardian.com')\n",
    "# # hit return after you enter search text\n",
    "# search.send_keys(Keys.RETURN) \n",
    "# #Sleep\n",
    "# time.sleep(10)\n",
    "# # Find the tool bar\n",
    "# element = driver.find_element_by_id('hdtb-tls')\n",
    "# driver.execute_script(\"arguments[0].click();\", element)\n",
    "# # Click on the date bar\n",
    "# element2 = driver.find_element_by_class_name('hdtb-mn-hd')\n",
    "# driver.execute_script(\"arguments[0].click();\", element2)\n",
    "# # Find the Customer Range menu\n",
    "# element3 = driver.find_element_by_class_name('ErsxPb.gvybPb')\n",
    "# driver.execute_script(\"arguments[0].click();\", element3)\n",
    "# # Click the Customer Range menu\n",
    "# time.sleep(3)\n",
    "# element4 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"lb\"]/div[2]/g-menu/g-menu-item[7]/div/div/span')))\n",
    "# # element4 = driver.find_element_by_xpath('//*[@id=\"lb\"]/div[2]/g-menu/g-menu-item[7]/div/div/span')\n",
    "# driver.execute_script(\"arguments[0].click();\", element4)\n",
    "# # Input Start Date\n",
    "# element5 = driver.find_element_by_xpath('//*[@id=\"OouJcb\"]')\n",
    "# element5.send_keys('23-03-2019')\n",
    "# # Input End Date\n",
    "# element6 = driver.find_element_by_xpath('//*[@id=\"rzG2be\"]')\n",
    "# element6.send_keys('23-03-2019')\n",
    "# time.sleep(5)\n",
    "\n",
    "# # Submit Date\n",
    "# element7 = driver.find_element_by_xpath('//*[@id=\"T3kYXe\"]/g-button')\n",
    "# driver.execute_script(\"arguments[0].click();\", element7)\n",
    "\n",
    "\n",
    "# ## get hrefs\n",
    "# results = driver.find_elements_by_css_selector('div.g')\n",
    "# time.sleep(5)\n",
    "# for i in range(len(results)):\n",
    "#     link = results[i].find_element_by_tag_name(\"a\")\n",
    "#     href = link.get_attribute(\"href\")\n",
    "#     print(href)\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         next_page = driver.find_element_by_xpath(\"//*[@id='pnnext']\").get_attribute(\"href\")\n",
    "#         driver.get(next_page)\n",
    "#         results = driver.find_elements_by_css_selector('div.g')\n",
    "#         time.sleep(5)\n",
    "#         for i in range(len(results)):\n",
    "#             link = results[i].find_element_by_tag_name(\"a\")\n",
    "#             href = link.get_attribute(\"href\")\n",
    "#             print(href)\n",
    "\n",
    "#     except:\n",
    "#         print(\"no more pages left\")\n",
    "#         driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get headlines from links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex for partial match with class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_headlines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(PATH)\n",
    "# driver.maximize_window()\n",
    "\n",
    "# wait = WebDriverWait(driver, 3)\n",
    "# presence = EC.presence_of_element_located\n",
    "# visible = EC.visibility_of_element_located\n",
    "\n",
    "# for i in list_headlines:\n",
    "#     driver.get(i)\n",
    "#     WebDriverWait(driver, 10)\n",
    "#     print(i)\n",
    "    \n",
    "#     try:\n",
    "#         divs = driver.find_element_by_css_selector(\"[class*='e-headline']\")\n",
    "#         real_headlines.append(divs.text)\n",
    "# #         print(divs.text)\n",
    "        \n",
    "#     except:\n",
    "#         divs = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_headlines\n",
    "# myset = set(real_headlines)\n",
    "# len(myset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(real_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(PATH)\n",
    "# driver.maximize_window()\n",
    "\n",
    "# wait = WebDriverWait(driver, 5)\n",
    "# presence = EC.presence_of_element_located\n",
    "# visible = EC.visibility_of_element_located\n",
    "\n",
    "# for website in websites_google_search:\n",
    "#     driver = webdriver.Chrome(PATH)\n",
    "#     driver.maximize_window()\n",
    "#     for day in search_days:\n",
    "#         driver.get(f'https://www.google.com/search?q=nhs+site:{website}&tbs=cdr:1,cd_min:{day},cd_max:{day}&sxsrf=ALeKk02Trw5YASvAO8g4qyRyb2eRf-Q2cg:1614704439315&ei=N28-YKrsEtHxxgPilIboDA&start=90&sa=N&ved=2ahUKEwjq45bkipLvAhXRuHEKHWKKAc0Q8tMDegQIAxBF&biw=1280&bih=614')\n",
    "#         while True:\n",
    "#             random_i = randint(5, 15)\n",
    "#             WebDriverWait(driver, random_i)\n",
    "#             next_page_btn =driver.find_elements_by_xpath(\"//a[@id='pnnext']\")\n",
    "#             if \n",
    "            \n",
    "#             elif len(next_page_btn) <1:\n",
    "#                 print(\"no more pages left\")\n",
    "#                 driver.quit()\n",
    "#                 break\n",
    "\n",
    "#             else:\n",
    "#                 random_i = randint(5, 15)\n",
    "#                 WebDriverWait(driver, random_i)\n",
    "#                 results = driver.find_elements_by_css_selector('div.g')\n",
    "#                 for i in range(len(results)):\n",
    "#                     link = results[i].find_element_by_tag_name(\"a\")\n",
    "#                     href = link.get_attribute(\"href\")\n",
    "#                     if website in href:\n",
    "#                         print(href)\n",
    "#                         list_headlines.append(href)\n",
    "#                 next_page = driver.find_element_by_xpath(\"//*[@id='pnnext']\").get_attribute(\"href\")\n",
    "#                 driver.get(next_page)\n",
    "            \n",
    "#             href = link.get_attribute(\"href\").click()\n",
    "#             random_i = randint(3, 5)\n",
    "#             WebDriverWait(driver, random_i)\n",
    "#             new_ = next_page.get_attribute(\"href\").click()\n",
    "#             print(new_)\n",
    "#             driver.Click()\n",
    "#             driver.next_page[0].get_attribute(\"href\").click()\n",
    "        \n",
    "# with open(\"all_h_refs.txt\", \"w\") as output:\n",
    "#     output.write(str(list_headlines))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for website in websites_google_search:\n",
    "#     driver = webdriver.Chrome(PATH)\n",
    "#     driver.maximize_window()\n",
    "#     for day in search_days:\n",
    "#         driver.get(f'https://www.google.com/search?q=nhs+site:{website}&tbs=cdr:1,cd_min:{day},cd_max:{day}&sxsrf=ALeKk02Trw5YASvAO8g4qyRyb2eRf-Q2cg:1614704439315&ei=N28-YKrsEtHxxgPilIboDA&start=90&sa=N&ved=2ahUKEwjq45bkipLvAhXRuHEKHWKKAc0Q8tMDegQIAxBF&biw=1280&bih=614')\n",
    "#         while True:\n",
    "#             random_i = randint(5, 15)\n",
    "#             WebDriverWait(driver, random_i)\n",
    "#             one_page_link = driver.find_elements_by_class_name('LC20lb')\n",
    "# #             if len(one_page_link) > 0: \n",
    "# #                 random_i = randint(5, 15)\n",
    "# #                 WebDriverWait(driver, random_i)\n",
    "# #                 results = driver.find_elements_by_css_selector('div.g')\n",
    "# #                 for i in range(len(results)):\n",
    "# #                     link = results[i].find_element_by_tag_name(\"a\")\n",
    "# #                     href = link.get_attribute(\"href\")\n",
    "# #                     if website in href:\n",
    "# #                         print(href)\n",
    "# #                         list_headlines.append(href)\n",
    "# #                 next_page = driver.find_element_by_xpath(\"//*[@id='pnnext']\").get_attribute(\"href\")\n",
    "# #                 driver.get(next_page)\n",
    "\n",
    "# #             else:\n",
    "# #                 print(\"no more pages left\")\n",
    "# #                 driver.quit()\n",
    "# #                 break\n",
    "            \n",
    "# with open(\"all_h_refs.txt\", \"w\") as output:\n",
    "#     output.write(str(list_headlines))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(PATH)\n",
    "# driver.maximize_window()\n",
    "\n",
    "# wait = WebDriverWait(driver, 5)\n",
    "# presence = EC.presence_of_element_located\n",
    "# visible = EC.visibility_of_element_located\n",
    "\n",
    "# # Navigate to url with video being appended to search_query\n",
    "# for website in websites_google_search:\n",
    "#     wait\n",
    "\n",
    "#     page_number_found = True\n",
    "#     while page_number_found == True:\n",
    "#         for date in search_days:\n",
    "#             try:\n",
    "#                 random_i = randint(5, 15)\n",
    "#                 WebDriverWait(driver, random_i)\n",
    "#                 driver.get(f'https://www.google.com/search?q=nhs+site:{website}&tbs=cdr:1,cd_min:{date},cd_max:{date}&sxsrf=ALeKk02IWAdbzTcOOTXprjips1JZGT3XxA:1614530791185&ei=58g7YMLpCq2O1fAP8JuQ0Ak&start={google_page_number}&sa=N&ved=2ahUKEwiC-aXyg43vAhUtRxUIHfANBJo4ChDy0wN6BAgDEDc&biw=1280&bih=614')\n",
    "#                 results = driver.find_elements_by_css_selector('div.g')\n",
    "#                 for i in range(len(results)):\n",
    "#                     wait\n",
    "#                     link = results[i].find_element_by_tag_name(\"a\")\n",
    "#                     href = link.get_attribute(\"href\")\n",
    "#                     print(href)\n",
    "\n",
    "\n",
    "#             except:\n",
    "#                 page_number_found == False\n",
    "#                 break\n",
    "\n",
    "#             google_page_number += 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
